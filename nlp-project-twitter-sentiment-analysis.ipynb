{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Projeto 2 - NLP\n\n-----","metadata":{"id":"362c03d1"}},{"cell_type":"markdown","source":" Usaremos os algoritmos aprendidos e as t√©cnicas vistas na segunda parte do curso para extrairmos informa√ß√µes relevantes de texto. Mais precisamente, de publica√ß√µes no Twitter.","metadata":{"id":"9517a372"}},{"cell_type":"markdown","source":"## Os Dados","metadata":{"id":"955a3a98"}},{"cell_type":"markdown","source":"Utilizaremos um Dataset obtido do Twitter com 100K postagens entre os dias 01/08/2018 e 20/10/2018. Cada postagem √© classificada como **positiva**, **negativa** ou **neutra**.  \n\nDescri√ß√£o das colunas:\n\n- **id**: ID √∫nico para o tweet  \n- **tweet_text**: Texto da publica√ß√£o no Twitter  \n- **tweet_date**: Data da publica√ß√£o no Twitter  \n- **sentiment**: 0, se negativo; 1, se positivo; 2, se neutro  \n- **query_used**: Filtro utilizado para buscar a publica√ß√£o","metadata":{"id":"237d5657"}},{"cell_type":"markdown","source":"## O Problema","metadata":{"id":"9dc86eb5"}},{"cell_type":"markdown","source":"Voc√™ dever√° desenvolver um modelo para detectar o sentimento de uma publica√ß√£o do Twitter a classificando em uma das tr√™s categorias: **positiva**, **negativa** ou **neutra**. O texto da publica√ß√£o est√° dispon√≠vel na coluna \"tweet_text\". Teste pelo menos 2 t√©cnicas de NLP diferentes e escolha a m√©trica de avalia√ß√£o que julgar mais pertinente.  \n\nPara ajudar no desenvolvimento, √© poss√≠vel dividir o projeto em algumas fases:\n\n- **An√°lise de consist√™ncia dos dados**: analise se os dados est√£o fazendo sentido, se os campos est√£o completos e se h√° dados duplicados ou faltantes. Se julgar necess√°rio, trate-os.    \n\n\n- **An√°lise explorat√≥ria**: analise a sua base como um todo, verifique o balanceamento entre as classes e foque, principalmente, na coluna ```tweet_text```.    \n\n\n- **Pr√©-processamento e transforma√ß√µes**: projetos de NLP exigem um consider√°vel pr√©-processamento. Foque no tratamento da string do texto. Procure come√ßar com tratamentos simples e adicione complexidade gradualmente. Nessa etapa voc√™ testar√° diferentes t√©cnicas de transforma√ß√µes, como o Bag Of Words e o TF-IDF.    \n\n\n- **Treinamento do modelo**: depois das transforma√ß√µes, voc√™ poder√° executar o treinamento do modelo classificador. Nessa etapa o problema se torna semelhante aos abordados na primeira parte do m√≥dulo. Voc√™ pode testar diversos classificadores como RandomForest, AdaBoost, entre outros. Otimize os hiperpar√¢metros do modelo com t√©cnicas como a GridSearch e a RandomizedSearch.    \n\n\n- **Conclus√µes**: descreva, em texto, as conclus√µes sobre os seus estudos. O modelo √© capaz de identificar o sentimento das publica√ß√µes? √â poss√≠vel extrapolar o modelo para outros contextos, como a an√°lise de sentimento de uma frase qualquer? Pense em quest√µes pertinentes e relevantes que voc√™ tenha obtido durante o desenvolvimento do projeto!     \n\n","metadata":{"id":"4b0e1f6f"}},{"cell_type":"markdown","source":"## Dicas\n     \n\n### Tente encontrar poss√≠veis vieses\n\n√â muito comum que modelos de NLP possuam fortes vieses, como a tend√™ncia de relacionar palavras espec√≠ficas com alguma classe de sa√≠da. Tente encontrar vieses no seu estudo, isso pode ajudar a tirar boas conclus√µes. o campo \"query_used\" pode ser √∫til para essa an√°lise.  \n\n### O pr√©-processamento √© a chave para um bom desempenho\n\nEssa √© a etapa que mais vai contribuir para o desempenho do seu modelo. Seja criativo e desenvolva essa etapa de uma maneira que seja f√°cil de aplicar o mesmo processamento para uma nova base, voc√™ ter√° que fazer isso para gerar a base de submiss√£o.\n\n-------","metadata":{"id":"2bb23437"}},{"cell_type":"markdown","source":"#### First, let's do the importing of the necessary libraries.","metadata":{}},{"cell_type":"code","source":"# Imports for Data Analysis\nimport pandas as pd\nimport numpy as np\n\n# Imports for Data-viz\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom wordcloud import WordCloud\n\n# Imports for image processing\nfrom skimage import feature\n\n# Imports for NLP\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem import RSLPStemmer\nfrom unidecode import unidecode\nfrom nltk.stem.porter import *\nfrom nltk import pos_tag\n\nimport string\nfrom unidecode import unidecode\nimport emoji\nimport spacy\nfrom spacy.lang.pt.examples import sentences \nimport re\n\nimport tensorflow.keras as keras\nfrom tensorflow.keras.preprocessing import sequence\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n\n# Imports for Cross-validation\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV,StratifiedKFold\n\n\n# Imports for Machine Learning\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom lightgbm import LGBMClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer,CountVectorizer\n\n\n# Imports for Deep Learning\nfrom tensorflow.keras.models import Sequential,load_model\nfrom tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPool2D, Flatten\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Embedding\n\n# Imports for Model Validation\nimport sklearn.metrics\nfrom sklearn.metrics import classification_report,ConfusionMatrixDisplay\nfrom sklearn.metrics import accuracy_score\n\n# Warning\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nfrom collections import Counter\nfrom time import time","metadata":{"execution":{"iopub.status.busy":"2022-09-14T21:01:12.433243Z","iopub.execute_input":"2022-09-14T21:01:12.433622Z","iopub.status.idle":"2022-09-14T21:01:12.478879Z","shell.execute_reply.started":"2022-09-14T21:01:12.433592Z","shell.execute_reply":"2022-09-14T21:01:12.477916Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"# Downloading the necessary packages\nnltk.download(\"stopwords\")\nnltk.download(\"punkt\")\nnltk.download(\"rslp\")\npt_stopwords = nltk.corpus.stopwords.words(\"portuguese\")\nspacy.cli.download(\"pt_core_news_sm\")","metadata":{"execution":{"iopub.status.busy":"2022-09-14T17:27:51.795962Z","iopub.execute_input":"2022-09-14T17:27:51.798583Z","iopub.status.idle":"2022-09-14T17:28:08.447790Z","shell.execute_reply.started":"2022-09-14T17:27:51.798548Z","shell.execute_reply":"2022-09-14T17:28:08.446405Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package rslp to /usr/share/nltk_data...\n[nltk_data]   Package rslp is already up-to-date!\n","output_type":"stream"},{"name":"stdout","text":"Collecting pt-core-news-sm==3.3.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.3.0/pt_core_news_sm-3.3.0-py3-none-any.whl (13.0 MB)\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13.0/13.0 MB 68.5 MB/s eta 0:00:00\nRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /opt/conda/lib/python3.7/site-packages (from pt-core-news-sm==3.3.0) (3.3.1)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.0.10)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.8.2)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (4.64.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.0.8)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.3.0)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.0.8)\nRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.10.1)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.4.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.4.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (59.8.0)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.28.1)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.7.8)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.0.3)\nRequirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.6.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (21.3)\nRequirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (8.0.17)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.0.7)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.1.2)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.21.6)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.0.6)\nCollecting typing-extensions<4.2.0,>=3.7.4\n  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.8.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.0.9)\nRequirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (5.2.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2022.6.15)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.26.12)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.1.0)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (8.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.1.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (4.12.0)\nInstalling collected packages: typing-extensions, pt-core-news-sm\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.3.0\n    Uninstalling typing_extensions-4.3.0:\n      Successfully uninstalled typing_extensions-4.3.0\n","output_type":"stream"},{"name":"stderr","text":"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\ntensorflow 2.6.4 requires h5py~=3.1.0, but you have h5py 3.7.0 which is incompatible.\ntensorflow 2.6.4 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\ntensorflow 2.6.4 requires tensorboard<2.7,>=2.6.0, but you have tensorboard 2.10.0 which is incompatible.\ntensorflow 2.6.4 requires typing-extensions<3.11,>=3.7, but you have typing-extensions 4.1.1 which is incompatible.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.6.4 which is incompatible.\npandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\nflax 0.6.0 requires rich~=11.1, but you have rich 12.1.0 which is incompatible.\nflake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.12.0 which is incompatible.\napache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\nallennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\naiobotocore 2.3.4 requires botocore<1.24.22,>=1.24.21, but you have botocore 1.27.56 which is incompatible.\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n","output_type":"stream"},{"name":"stdout","text":"Successfully installed pt-core-news-sm-3.3.0 typing-extensions-4.1.1\n\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('pt_core_news_sm')\n","output_type":"stream"}]},{"cell_type":"code","source":"#Instantiates the PorterStemmer\nstemmer = PorterStemmer()","metadata":{"execution":{"iopub.status.busy":"2022-09-14T17:28:08.450196Z","iopub.execute_input":"2022-09-14T17:28:08.450536Z","iopub.status.idle":"2022-09-14T17:28:08.461472Z","shell.execute_reply.started":"2022-09-14T17:28:08.450500Z","shell.execute_reply":"2022-09-14T17:28:08.457888Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Analysis Set up","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:57:55.334129Z","iopub.execute_input":"2022-09-09T15:57:55.334830Z","iopub.status.idle":"2022-09-09T15:57:55.344201Z","shell.execute_reply.started":"2022-09-09T15:57:55.334784Z","shell.execute_reply":"2022-09-09T15:57:55.342431Z"}}},{"cell_type":"code","source":"# Reading the training dataset \ndf_complete = pd.read_csv(\"../input/train3classes/Train3Classes.csv\")\ndf_complete","metadata":{"id":"3b6d2b81","outputId":"55db3704-413c-4649-9507-418ae43efb1a","execution":{"iopub.status.busy":"2022-09-14T17:28:08.462438Z","iopub.execute_input":"2022-09-14T17:28:08.462696Z","iopub.status.idle":"2022-09-14T17:28:09.054114Z","shell.execute_reply.started":"2022-09-14T17:28:08.462672Z","shell.execute_reply":"2022-09-14T17:28:09.053079Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                        id                                         tweet_text  \\\n0      1049721159292346368  Rio elege maior bancada policial de sua hist√≥r...   \n1      1046251157025423360  fiquei t√£o triste quando eu vi o pre√ßo da c√¢me...   \n2      1041744620206653440  Para Theresa May, seu plano para o Brexit √© a ...   \n3      1046937084727107589  caralho eu quero proteger a danielly em um pot...   \n4      1047326854229778432                         @SiCaetano_ viva o caos :)   \n...                    ...                                                ...   \n94995  1041831666883321856  Cuba e defensor de direitos humanos se unem co...   \n94996  1032352892194369536  #Oportunidade ‚û°Ô∏è Venha fazer parte da nossa eq...   \n94997  1046785538542440448  @96syoo EU SEI üò≠üò≠ √© por isso que significa mui...   \n94998  1045457469110177792            @louistsexhes N te conhe√ßo mas posta :D   \n94999  1046239135286136832                meu deus :( https://t.co/BlXazxZeKq   \n\n                           tweet_date  sentiment     query_used  \n0      Tue Oct 09 18:00:01 +0000 2018          2          folha  \n1      Sun Sep 30 04:11:28 +0000 2018          0             :(  \n2      Mon Sep 17 17:44:06 +0000 2018          2          exame  \n3      Tue Oct 02 01:37:06 +0000 2018          0             :(  \n4      Wed Oct 03 03:25:55 +0000 2018          1             :)  \n...                               ...        ...            ...  \n94995  Mon Sep 17 23:30:00 +0000 2018          2   jornaloglobo  \n94996  Wed Aug 22 19:44:44 +0000 2018          2  #oportunidade  \n94997  Mon Oct 01 15:34:55 +0000 2018          0             :(  \n94998  Thu Sep 27 23:37:38 +0000 2018          1             :)  \n94999  Sun Sep 30 03:23:42 +0000 2018          0             :(  \n\n[95000 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet_text</th>\n      <th>tweet_date</th>\n      <th>sentiment</th>\n      <th>query_used</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1049721159292346368</td>\n      <td>Rio elege maior bancada policial de sua hist√≥r...</td>\n      <td>Tue Oct 09 18:00:01 +0000 2018</td>\n      <td>2</td>\n      <td>folha</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1046251157025423360</td>\n      <td>fiquei t√£o triste quando eu vi o pre√ßo da c√¢me...</td>\n      <td>Sun Sep 30 04:11:28 +0000 2018</td>\n      <td>0</td>\n      <td>:(</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1041744620206653440</td>\n      <td>Para Theresa May, seu plano para o Brexit √© a ...</td>\n      <td>Mon Sep 17 17:44:06 +0000 2018</td>\n      <td>2</td>\n      <td>exame</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1046937084727107589</td>\n      <td>caralho eu quero proteger a danielly em um pot...</td>\n      <td>Tue Oct 02 01:37:06 +0000 2018</td>\n      <td>0</td>\n      <td>:(</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1047326854229778432</td>\n      <td>@SiCaetano_ viva o caos :)</td>\n      <td>Wed Oct 03 03:25:55 +0000 2018</td>\n      <td>1</td>\n      <td>:)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94995</th>\n      <td>1041831666883321856</td>\n      <td>Cuba e defensor de direitos humanos se unem co...</td>\n      <td>Mon Sep 17 23:30:00 +0000 2018</td>\n      <td>2</td>\n      <td>jornaloglobo</td>\n    </tr>\n    <tr>\n      <th>94996</th>\n      <td>1032352892194369536</td>\n      <td>#Oportunidade ‚û°Ô∏è Venha fazer parte da nossa eq...</td>\n      <td>Wed Aug 22 19:44:44 +0000 2018</td>\n      <td>2</td>\n      <td>#oportunidade</td>\n    </tr>\n    <tr>\n      <th>94997</th>\n      <td>1046785538542440448</td>\n      <td>@96syoo EU SEI üò≠üò≠ √© por isso que significa mui...</td>\n      <td>Mon Oct 01 15:34:55 +0000 2018</td>\n      <td>0</td>\n      <td>:(</td>\n    </tr>\n    <tr>\n      <th>94998</th>\n      <td>1045457469110177792</td>\n      <td>@louistsexhes N te conhe√ßo mas posta :D</td>\n      <td>Thu Sep 27 23:37:38 +0000 2018</td>\n      <td>1</td>\n      <td>:)</td>\n    </tr>\n    <tr>\n      <th>94999</th>\n      <td>1046239135286136832</td>\n      <td>meu deus :( https://t.co/BlXazxZeKq</td>\n      <td>Sun Sep 30 03:23:42 +0000 2018</td>\n      <td>0</td>\n      <td>:(</td>\n    </tr>\n  </tbody>\n</table>\n<p>95000 rows √ó 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Checking the information of our dataset for training\n\nprint(\"Information of our dataset for training \\n Total Rows | Total Columns | Total of Null Values | Type\")\nprint(df_complete.info())","metadata":{"execution":{"iopub.status.busy":"2022-09-14T17:28:09.056201Z","iopub.execute_input":"2022-09-14T17:28:09.056805Z","iopub.status.idle":"2022-09-14T17:28:09.090948Z","shell.execute_reply.started":"2022-09-14T17:28:09.056764Z","shell.execute_reply":"2022-09-14T17:28:09.089899Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Information of our dataset for training \n Total Rows | Total Columns | Total of Null Values | Type\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 95000 entries, 0 to 94999\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   id          95000 non-null  int64 \n 1   tweet_text  95000 non-null  object\n 2   tweet_date  95000 non-null  object\n 3   sentiment   95000 non-null  int64 \n 4   query_used  95000 non-null  object\ndtypes: int64(2), object(3)\nmemory usage: 3.6+ MB\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"# Checking the values of the queries used while searching subjects\n\ndf_complete[\"query_used\"].value_counts()","metadata":{"id":"d9b83de9","outputId":"211ec860-caf2-4445-8d98-e32178055174","execution":{"iopub.status.busy":"2022-09-14T17:28:11.146920Z","iopub.execute_input":"2022-09-14T17:28:11.147549Z","iopub.status.idle":"2022-09-14T17:28:11.158591Z","shell.execute_reply.started":"2022-09-14T17:28:11.147516Z","shell.execute_reply":"2022-09-14T17:28:11.157583Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":":(               31696\n:)               31678\nfolha             5004\nestadao           3880\n#fato             3471\ng1                3439\nexame             3417\n#trabalho         3030\n#oportunidade     2455\njornaloglobo      2374\nveja              2141\n#noticia          1114\n#novidade          920\n#curiosidade       381\nName: query_used, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Checking value for each sentiment classification\n\ndf_complete[\"sentiment\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-09-14T17:28:14.804106Z","iopub.execute_input":"2022-09-14T17:28:14.805118Z","iopub.status.idle":"2022-09-14T17:28:14.814186Z","shell.execute_reply.started":"2022-09-14T17:28:14.805071Z","shell.execute_reply":"2022-09-14T17:28:14.813272Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0    31696\n1    31678\n2    31626\nName: sentiment, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Checking for missing values at the original dataset\n\nprint(f\"Missing Data:\", df_complete.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2022-09-14T17:28:16.980004Z","iopub.execute_input":"2022-09-14T17:28:16.980383Z","iopub.status.idle":"2022-09-14T17:28:17.004388Z","shell.execute_reply.started":"2022-09-14T17:28:16.980351Z","shell.execute_reply":"2022-09-14T17:28:17.003287Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Missing Data: id            0\ntweet_text    0\ntweet_date    0\nsentiment     0\nquery_used    0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Important Considerations Regarding This Database","metadata":{}},{"cell_type":"markdown","source":"#### After checking the information of the dataset as well as the business need for this project, the first decision was to exclude the unnecessary columns, focusing on the relevant data.","metadata":{}},{"cell_type":"markdown","source":"After analyzing the initial information, it‚Äôs possible to see that there are no null values in this dataset, the ‚Äú*ID*‚Äù column is numerical as well as ‚Äú*sentiment*‚Äù.\n\n   Please mind that, if this was a case in which it was necessary to assess a unique user‚Äôs tweeting multiple times about a subject or even how many times a specific user contacted a brand via Twitter, this column would be necessary to measure the sentiment throughout the time. However, in this specific scenario, since the database is massive and a brand‚Äôs interaction with its user base is not being assessed at the moment, it will be rather difficult to check that specificity.\n    \nThe same is valid for the column ‚Äútweet_date‚Äù, which would provide insights in case this dataset was measuring how many specific users had a negative sentiment towards a brand/product in a specific date, say that in that occasion some issue happened heavily affecting the general public.\n\nSince the aforementioned is not true to the problem proposed in this project, hence the decision to eliminate both the ‚Äú*ID*‚Äù and ‚Äú*tweet_date*‚Äù column was made.\n\n   On a further analysis, the class aimed for prediction is already balanced without the need to further tweak it. \nFurthermore, the column ‚Äú*tweet_text*‚Äù not only has a bunch of emojis, online laughter such as ‚Äú*kkkkkk*‚Äù, ‚Äú*rsrsrsr*‚Äù, ‚Äú*hahahah*‚Äù etc., and punctuation representing feelings, as the **sad smiley face** represented by the symbol ‚Äú :(‚Äú, it also has user mentions, hashtags and urls; which are all irrelevant to our analysis at this point.\n\nAs the column ‚Äú*query_used*‚Äù represents the search made at *Twitter* to find the relevant *Tweets* belonging to this database, it‚Äôs possible to observe that whenever the sad emoji symbol appears both in the query and at the *tweet* itself, the sentiment is tagged negatively; the same is true for the happy face emoji.\n\n   At first, it had been decided to create a dictionary and a function to handle this scenario, changing the smiley codes to their values, such as ‚Äúhappy‚Äù, ‚Äúsad‚Äù, and ‚Äúneutral‚Äù, starting the preprocessing and data cleaning. \nNonetheless, upon further appraisal it became clear that this phenomenon is attributed to the way this database was assembled which would represent a terrible data leak into the model if this decision were to be kept.\n**Thus, the column ‚Äúquery_used‚Äù will also be removed from our training data**.\n","metadata":{}},{"cell_type":"code","source":"# Creating a copy of the original dataframe\ndf_train = df_complete.copy()\n\n# Creating an unprocessed dataset based on the complete version, removing the irrelevant columns.\ndf_train = df_complete[[\"tweet_text\", \"sentiment\"]]\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-09-14T17:28:26.619588Z","iopub.execute_input":"2022-09-14T17:28:26.620030Z","iopub.status.idle":"2022-09-14T17:28:26.650616Z","shell.execute_reply.started":"2022-09-14T17:28:26.619988Z","shell.execute_reply":"2022-09-14T17:28:26.649581Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                              tweet_text  sentiment\n0      Rio elege maior bancada policial de sua hist√≥r...          2\n1      fiquei t√£o triste quando eu vi o pre√ßo da c√¢me...          0\n2      Para Theresa May, seu plano para o Brexit √© a ...          2\n3      caralho eu quero proteger a danielly em um pot...          0\n4                             @SiCaetano_ viva o caos :)          1\n...                                                  ...        ...\n94995  Cuba e defensor de direitos humanos se unem co...          2\n94996  #Oportunidade ‚û°Ô∏è Venha fazer parte da nossa eq...          2\n94997  @96syoo EU SEI üò≠üò≠ √© por isso que significa mui...          0\n94998            @louistsexhes N te conhe√ßo mas posta :D          1\n94999                meu deus :( https://t.co/BlXazxZeKq          0\n\n[95000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Rio elege maior bancada policial de sua hist√≥r...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fiquei t√£o triste quando eu vi o pre√ßo da c√¢me...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Para Theresa May, seu plano para o Brexit √© a ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>caralho eu quero proteger a danielly em um pot...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@SiCaetano_ viva o caos :)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94995</th>\n      <td>Cuba e defensor de direitos humanos se unem co...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>94996</th>\n      <td>#Oportunidade ‚û°Ô∏è Venha fazer parte da nossa eq...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>94997</th>\n      <td>@96syoo EU SEI üò≠üò≠ √© por isso que significa mui...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>94998</th>\n      <td>@louistsexhes N te conhe√ßo mas posta :D</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>94999</th>\n      <td>meu deus :( https://t.co/BlXazxZeKq</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>95000 rows √ó 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Checking for duplicates\nprint(\"Duplicated information:\", df_train.duplicated().sum())","metadata":{"execution":{"iopub.status.busy":"2022-09-14T17:28:29.554211Z","iopub.execute_input":"2022-09-14T17:28:29.554691Z","iopub.status.idle":"2022-09-14T17:28:29.664807Z","shell.execute_reply.started":"2022-09-14T17:28:29.554654Z","shell.execute_reply":"2022-09-14T17:28:29.663748Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Duplicated information: 815\n","output_type":"stream"}]},{"cell_type":"code","source":"# Removing the duplicated information\ndf_train.drop_duplicates(inplace = True)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-09-14T17:28:32.080313Z","iopub.execute_input":"2022-09-14T17:28:32.080761Z","iopub.status.idle":"2022-09-14T17:28:32.180837Z","shell.execute_reply.started":"2022-09-14T17:28:32.080724Z","shell.execute_reply":"2022-09-14T17:28:32.179810Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                              tweet_text  sentiment\n0      Rio elege maior bancada policial de sua hist√≥r...          2\n1      fiquei t√£o triste quando eu vi o pre√ßo da c√¢me...          0\n2      Para Theresa May, seu plano para o Brexit √© a ...          2\n3      caralho eu quero proteger a danielly em um pot...          0\n4                             @SiCaetano_ viva o caos :)          1\n...                                                  ...        ...\n94995  Cuba e defensor de direitos humanos se unem co...          2\n94996  #Oportunidade ‚û°Ô∏è Venha fazer parte da nossa eq...          2\n94997  @96syoo EU SEI üò≠üò≠ √© por isso que significa mui...          0\n94998            @louistsexhes N te conhe√ßo mas posta :D          1\n94999                meu deus :( https://t.co/BlXazxZeKq          0\n\n[94185 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Rio elege maior bancada policial de sua hist√≥r...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fiquei t√£o triste quando eu vi o pre√ßo da c√¢me...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Para Theresa May, seu plano para o Brexit √© a ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>caralho eu quero proteger a danielly em um pot...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@SiCaetano_ viva o caos :)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94995</th>\n      <td>Cuba e defensor de direitos humanos se unem co...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>94996</th>\n      <td>#Oportunidade ‚û°Ô∏è Venha fazer parte da nossa eq...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>94997</th>\n      <td>@96syoo EU SEI üò≠üò≠ √© por isso que significa mui...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>94998</th>\n      <td>@louistsexhes N te conhe√ßo mas posta :D</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>94999</th>\n      <td>meu deus :( https://t.co/BlXazxZeKq</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>94185 rows √ó 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Consideration after checking the tokenization\n- Based on the tokenization above, it's possible to see that some of the emojis weren't identified properly and got split in the process; therefore, it's necessary to use the emoji library to treat it and remove those entirely, which could lead to a different sentiment classification in our model.","metadata":{}},{"cell_type":"markdown","source":" - Excluir colunas \"id\" e \"tweet_date\"\n - Remover caracteres especias: @ (c√≥digo Regex: \"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)\")\n - Remover: o que come√ßa com \"http\", Emojis que n√£o expressam sentimentos (deixar somente os que expressam algum sentimento)\n - Remover d√≠gitos?\n - N√£o mexer na letra (caixa baixa ou alta)\n - Remover acentos\n - Emojis: ver biblioteca de emojis pastristea nas primeiras aulas","metadata":{"id":"60164722"}},{"cell_type":"markdown","source":"# Auxiliary Functions ","metadata":{}},{"cell_type":"markdown","source":"#### In order to preprocess this dataset to treat and clean our data, it will be necessary to have a few auxiliary functions to speed-up the process.","metadata":{}},{"cell_type":"code","source":"class PreProcessing:\n    \n    '''\n    This class contains a set of functions created to apply some preprocessing items into the data so it's possible to clean it up a bit.\n    '''\n\n        \n    def remove_query(self, string):\n        '''\n        Removes the query used\n        '''\n        string = re.sub(\"#fato|#novidade|#noticia|#curiosidade|#oportunidade|#trabalho\",\" \", string)\n        return string\n\n    \n    def remove_lexicalstress(self, string):\n        '''\n        Removes the lexical stress pattern as we're dealing with Brazilian grammar\n        '''\n        br_lexical = unidecode(string)\n        return br_lexical\n    \n    def remove_username(self, string):\n        '''\n        Removes @ and the user names\n        '''\n        username = r\"@[a-zA-Z0-9_.]+\"\n        remove_username = re.sub(username,\"\", string)\n        return remove_username\n\n    def remove_digits(self, string):\n        '''\n        Removes digits\n        '''\n        remove_digits = re.sub(r\"\\d*\", \"\", string)\n        return remove_digits\n    \n    \n    def punctuation_remove(self, string):\n        '''\n        This removes punctuation marks of our string\n        '''\n        punctuation_remove = re.sub(r\"[^\\w\\s]\",\"\", string)\n        return punctuation_remove\n    \n    def remove_links (self, string):\n        '''\n        Removes links\n        '''\n        url = r\"[a-zA-Z0-9]+://[a-zA-Z0-9.-_]+/[a-zA-Z0-9]+\"\n        remove_links = re.sub(url,\" \", string)\n        return remove_links\n    \n    def remove_emoji (self, string):\n        '''\n        Removes the emojis\n        '''\n        tweet_emoji = emoji.replace_emoji(string, replace=\"\").lower()\n        return tweet_emoji\n\n\n    def remove_special(self, string):\n        '''\n        This function removes special characters of a string\n        '''\n        remove_characters = re.sub(r\"[^a-zA-Z ]\",\" \", string)\n        return remove_characters\n\n\n    def tokenization(self, string):\n        '''\n        This function applies the tokenization in the string\n        '''\n        words = word_tokenize(string)\n        return words\n    \n    def removes_stopwords (self, string):\n        '''\n        This function removes brazilian portuguese stopwords\n        '''    \n        filtered_words = []\n        for word in string:\n            if not word in pt_stopwords:\n                filtered_words.append(word)\n        \n        return filtered_words\n\n    def stemming(self, string):\n        '''\n        This function applies the stemmer into our string.\n        \n        It was cordially provided by our colleague Erivan Oliveira and his group.\n        Since we are both studying at the same institution and had the same assignment. \n        '''\n        stemmer = RSLPStemmer()\n        filtered_words = []\n        for word in string:\n            filtered_words.append(stemmer.stem(word))\n        return filtered_words\n    \n    #def lemmatization (self, string):\n        '''\n        Applies lemmatization\n        This step was created together with professor Cec√≠lia Fl√°via while ministering classes on the concept of NLP\n        '''\n        #filtered_words = \" \".join(list)\n        \n        #nlp = spacy.load(\"pt_core_news_sm\")\n        #doc = nlp(filtered_words)\n        #tokens = [token for token in doc]\n        \n        #filtered_words = [token.lemma_ for token in doc]\n        \n        #return filtered_words\n\n    def lemmatization(self, string):\n        '''\n        This function applies the stemmer into our string.\n        \n        It was cordially provided by our colleague Erivan Oliveira and his group.\n        Since we are both studying at the same institution and had the same assignment. \n        '''\n        filtered_words = []\n        for word in string:\n            filtered_words.append(nlp(word)[0].lemma_)\n        return filtered_words\n\n    def pipeline(self, string, methods):\n        \n        preprocessing_steps = {\n            \"remove_query\":self.remove_query,\n            \"remove_lexicalstress\": self.remove_lexicalstress,\n            \"remove_username\": self.remove_username,\n            \"remove_digits\":self.remove_digits,\n            \"punctuation_remove\":self.punctuation_remove,\n            \"remove_links\":self.remove_links,\n            \"remove_emoji\":self.remove_emoji,\n            \"remove_special\":self.remove_special,\n            \"tokenization\":self.tokenization,\n            \"removes_stopwords\":self.removes_stopwords,\n            \"stemming\":self.stemming,\n            \"lemmatization\":self.lemmatization\n        }\n        \n        for method in methods:\n            string = preprocessing_steps[method](string)\n        return string\n    ","metadata":{"execution":{"iopub.status.busy":"2022-09-14T17:28:37.211725Z","iopub.execute_input":"2022-09-14T17:28:37.212462Z","iopub.status.idle":"2022-09-14T17:28:37.230305Z","shell.execute_reply.started":"2022-09-14T17:28:37.212420Z","shell.execute_reply":"2022-09-14T17:28:37.229178Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def removal_words(x,dictionary):\n    '''\n    This function was created to assess the frequency of words for this dataset\n    '''\n    removal_by_frequency = []\n    for i in x:\n        if i in repetition_freq[repetition_freq>10].index:\n            removal_by_frequency.append(i)\n    return removal_by_frequency    ","metadata":{"execution":{"iopub.status.busy":"2022-09-14T17:28:40.425389Z","iopub.execute_input":"2022-09-14T17:28:40.426204Z","iopub.status.idle":"2022-09-14T17:28:40.433876Z","shell.execute_reply.started":"2022-09-14T17:28:40.426167Z","shell.execute_reply":"2022-09-14T17:28:40.430471Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def clf_metrics(estimator, X_train, X_test, y_train, y_test):\n    \n    '''\n    This function is used to assess the metrics of the given model.\n    '''\n    \n    print(\"# ============================================\")\n    \n    print(\"\\nTraining Assessment Metrics:\\n\")\n    \n    y_pred_train = estimator.predict(X_train)\n    \n    ConfusionMatrixDisplay.from_predictions(y_train, y_pred_train,cmap=\"plasma\")\n    plt.show()\n    \n    print(classification_report(y_train, y_pred_train))\n    \n    print(\"# ============================================\")\n\n    print(\"\\nTest Assessment Metrics:\\n\")\n\n    y_pred_test = estimator.predict(X_test)\n    \n    ConfusionMatrixDisplay.from_predictions(y_test, y_pred_test,cmap=\"plasma\")\n    plt.show()\n\n    print(classification_report(y_test, y_pred_test))","metadata":{"execution":{"iopub.status.busy":"2022-09-14T20:18:44.604733Z","iopub.execute_input":"2022-09-14T20:18:44.605354Z","iopub.status.idle":"2022-09-14T20:18:44.611892Z","shell.execute_reply.started":"2022-09-14T20:18:44.605317Z","shell.execute_reply":"2022-09-14T20:18:44.610698Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def neural_network_clf(estimator, X_train, X_test, y_train, y_test):\n    '''\n    This function is used to assess the classification metrics of the neural network model.\n    '''\n    \n    print(\"# ============================================\")\n    \n    print(\"\\nTraining Assessment Metrics:\\n\")\n\n    y_pred_train = estimator.predict(X_train)\n    y_pred_train = np.argmax(y_pred_train) \n\n\n    ConfusionMatrixDisplay.from_predictions(y_train, y_pred_train, cmap=\"plasma\")\n    plt.show()\n\n    print(classification_report(y_train, y_pred_train))\n\n    print(\"# ============================================\")\n\n    print(\"\\nTest Assessment Metrics:\\n\")\n\n    y_pred_test = estimator.predict(X_test)\n    y_pred_test = np.argmax(y_pred_test, axis=1) \n\n    ConfusionMatrixDisplay.from_predictions(y_test, y_pred_test, cmap=\"plasma\")\n    plt.show()\n\n    print(classification_report(y_test, y_pred_test))\n","metadata":{"execution":{"iopub.status.busy":"2022-09-14T20:39:37.246045Z","iopub.execute_input":"2022-09-14T20:39:37.246434Z","iopub.status.idle":"2022-09-14T20:39:37.256436Z","shell.execute_reply.started":"2022-09-14T20:39:37.246403Z","shell.execute_reply":"2022-09-14T20:39:37.253636Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":"#### Since this dataset is gigantic, in order to first test the preprocessing function and cleaning of data, it's necessary to create a fraction of it.","metadata":{}},{"cell_type":"code","source":"# Creating a fraction of this dataset since it's too big and we first want to check if our code works.\ndf_trainsample = df_train.sample(frac=0.01, replace=False)","metadata":{"execution":{"iopub.status.busy":"2022-09-14T17:29:01.877353Z","iopub.execute_input":"2022-09-14T17:29:01.877707Z","iopub.status.idle":"2022-09-14T17:29:01.887666Z","shell.execute_reply.started":"2022-09-14T17:29:01.877677Z","shell.execute_reply":"2022-09-14T17:29:01.886666Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Calling the class to set the pipeline in motion with the process needed to clean this dataset\nnlp = spacy.load(\"pt_core_news_sm\")\npt_stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n\npreprocess = PreProcessing()\npipeline = [\n    \"remove_query\",\n    \"remove_lexicalstress\",\n    \"remove_username\",\n    \"remove_digits\",\n    \"punctuation_remove\",\n    \"remove_links\",\n    \"remove_emoji\",\n    \"remove_special\",\n    \"tokenization\",\n    \"removes_stopwords\",\n    \"stemming\",\n    \"lemmatization\"\n]","metadata":{"execution":{"iopub.status.busy":"2022-09-14T17:29:08.887922Z","iopub.execute_input":"2022-09-14T17:29:08.888839Z","iopub.status.idle":"2022-09-14T17:29:09.368503Z","shell.execute_reply.started":"2022-09-14T17:29:08.888786Z","shell.execute_reply":"2022-09-14T17:29:09.367511Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"%%time\n# Preprocessing stage creating the columns for Processed Tweet and Joined Tweet after being processed and cleaned\ndf_trainsample[\"processed_tweet\"] = df_trainsample[\"tweet_text\"].apply(preprocess.pipeline, methods = pipeline)\n\ndf_trainsample","metadata":{"execution":{"iopub.status.busy":"2022-09-14T17:29:15.369130Z","iopub.execute_input":"2022-09-14T17:29:15.369822Z","iopub.status.idle":"2022-09-14T17:29:59.829204Z","shell.execute_reply.started":"2022-09-14T17:29:15.369786Z","shell.execute_reply":"2022-09-14T17:29:59.828287Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"CPU times: user 44.2 s, sys: 50 ms, total: 44.2 s\nWall time: 44.4 s\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                              tweet_text  sentiment  \\\n19288                         @VivienVillones Depende :)          1   \n29349  Vendedora - Loja de Brinquedos e Presentes - S...          2   \n60313                      Hoje vou voltar √° nata√ß√£o :))          1   \n90821  Fds espero que isto passe pq n quero faltar a ...          1   \n42564  @duze_rick Jamal, voc√™ pode tentar o aumento d...          1   \n...                                                  ...        ...   \n26578             @S18NU To emocionado, a. Seu lindo. :(          0   \n60029  @marcao97fm @co1_gregory @estadio97 @domenico9...          2   \n3482   \"Lembra quando voc√™ era crian√ßa, e voc√™ sonhav...          2   \n59000  queria ser compreendida pelo menos uma vez na ...          0   \n55525  BNDES ir√° financiar concess√£o da Rodovia de In...          2   \n\n                                         processed_tweet  \n19288                                           [depend]  \n29349  [vend, loj, brinqued, pr, Sao, Paul, sp, https...  \n60313                            [hoj, ir, volt, Nataca]  \n90821  [fd, esper, passr, pqr, n, querer, falt, trein...  \n42564  [Jamal, voc, pod, Tent, aument, Limit, aplic, ...  \n...                                                  ...  \n26578                                [to, Emocion, lind]  \n60029  [mesmo, mesmov, ver, ir, enta, katzoporr, fat,...  \n3482   [lembr, voc, crianc, voc, sonh, don, Mund, cri...  \n59000               [querer, Compreend, menos, vez, vid]  \n55525  [bnd, ira, Financi, concessa, Rodov, integraco...  \n\n[942 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_text</th>\n      <th>sentiment</th>\n      <th>processed_tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19288</th>\n      <td>@VivienVillones Depende :)</td>\n      <td>1</td>\n      <td>[depend]</td>\n    </tr>\n    <tr>\n      <th>29349</th>\n      <td>Vendedora - Loja de Brinquedos e Presentes - S...</td>\n      <td>2</td>\n      <td>[vend, loj, brinqued, pr, Sao, Paul, sp, https...</td>\n    </tr>\n    <tr>\n      <th>60313</th>\n      <td>Hoje vou voltar √° nata√ß√£o :))</td>\n      <td>1</td>\n      <td>[hoj, ir, volt, Nataca]</td>\n    </tr>\n    <tr>\n      <th>90821</th>\n      <td>Fds espero que isto passe pq n quero faltar a ...</td>\n      <td>1</td>\n      <td>[fd, esper, passr, pqr, n, querer, falt, trein...</td>\n    </tr>\n    <tr>\n      <th>42564</th>\n      <td>@duze_rick Jamal, voc√™ pode tentar o aumento d...</td>\n      <td>1</td>\n      <td>[Jamal, voc, pod, Tent, aument, Limit, aplic, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26578</th>\n      <td>@S18NU To emocionado, a. Seu lindo. :(</td>\n      <td>0</td>\n      <td>[to, Emocion, lind]</td>\n    </tr>\n    <tr>\n      <th>60029</th>\n      <td>@marcao97fm @co1_gregory @estadio97 @domenico9...</td>\n      <td>2</td>\n      <td>[mesmo, mesmov, ver, ir, enta, katzoporr, fat,...</td>\n    </tr>\n    <tr>\n      <th>3482</th>\n      <td>\"Lembra quando voc√™ era crian√ßa, e voc√™ sonhav...</td>\n      <td>2</td>\n      <td>[lembr, voc, crianc, voc, sonh, don, Mund, cri...</td>\n    </tr>\n    <tr>\n      <th>59000</th>\n      <td>queria ser compreendida pelo menos uma vez na ...</td>\n      <td>0</td>\n      <td>[querer, Compreend, menos, vez, vid]</td>\n    </tr>\n    <tr>\n      <th>55525</th>\n      <td>BNDES ir√° financiar concess√£o da Rodovia de In...</td>\n      <td>2</td>\n      <td>[bnd, ira, Financi, concessa, Rodov, integraco...</td>\n    </tr>\n  </tbody>\n</table>\n<p>942 rows √ó 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Now that the preprocessing was tested and worked according to what was expected, it's time to apply this into the training dataset.","metadata":{}},{"cell_type":"code","source":"%%time\n# Preprocessing stage creating the columns for Processed Tweet and Joined Tweet after being processed and cleaned\ndf_train[\"processed_tweet\"] = df_train[\"tweet_text\"].apply(preprocess.pipeline, methods = pipeline)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-09-14T17:29:59.831292Z","iopub.execute_input":"2022-09-14T17:29:59.832333Z","iopub.status.idle":"2022-09-14T18:41:56.683499Z","shell.execute_reply.started":"2022-09-14T17:29:59.832296Z","shell.execute_reply":"2022-09-14T18:41:56.682426Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"CPU times: user 1h 11min 30s, sys: 4.65 s, total: 1h 11min 35s\nWall time: 1h 11min 56s\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                                              tweet_text  sentiment  \\\n0      Rio elege maior bancada policial de sua hist√≥r...          2   \n1      fiquei t√£o triste quando eu vi o pre√ßo da c√¢me...          0   \n2      Para Theresa May, seu plano para o Brexit √© a ...          2   \n3      caralho eu quero proteger a danielly em um pot...          0   \n4                             @SiCaetano_ viva o caos :)          1   \n...                                                  ...        ...   \n94995  Cuba e defensor de direitos humanos se unem co...          2   \n94996  #Oportunidade ‚û°Ô∏è Venha fazer parte da nossa eq...          2   \n94997  @96syoo EU SEI üò≠üò≠ √© por isso que significa mui...          0   \n94998            @louistsexhes N te conhe√ßo mas posta :D          1   \n94999                meu deus :( https://t.co/BlXazxZeKq          0   \n\n                                         processed_tweet  \n0      [Rio, eleg, mai, banc, polic, hist, Httpstcosg...  \n1                      [fiq, tao, trist, ver, prec, car]  \n2      [ther, may, plan, brexit, unic, opca, httpstco...  \n3         [caralh, querer, proteg, danielly, pot, tadir]  \n4                                             [viv, Cao]  \n...                                                  ...  \n94995  [cub, defen, direit, human, un, contr, chefr, ...  \n94996  [oportunr, venh, fazer, part, equip, vag, Aber...  \n94997  [saber, signif, to, feliz, demal, amo, aqu, pr...  \n94998                              [n, conhec, postr, d]  \n94999                          [dar, httpstcoblxazxzekq]  \n\n[94185 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_text</th>\n      <th>sentiment</th>\n      <th>processed_tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Rio elege maior bancada policial de sua hist√≥r...</td>\n      <td>2</td>\n      <td>[Rio, eleg, mai, banc, polic, hist, Httpstcosg...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fiquei t√£o triste quando eu vi o pre√ßo da c√¢me...</td>\n      <td>0</td>\n      <td>[fiq, tao, trist, ver, prec, car]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Para Theresa May, seu plano para o Brexit √© a ...</td>\n      <td>2</td>\n      <td>[ther, may, plan, brexit, unic, opca, httpstco...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>caralho eu quero proteger a danielly em um pot...</td>\n      <td>0</td>\n      <td>[caralh, querer, proteg, danielly, pot, tadir]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@SiCaetano_ viva o caos :)</td>\n      <td>1</td>\n      <td>[viv, Cao]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94995</th>\n      <td>Cuba e defensor de direitos humanos se unem co...</td>\n      <td>2</td>\n      <td>[cub, defen, direit, human, un, contr, chefr, ...</td>\n    </tr>\n    <tr>\n      <th>94996</th>\n      <td>#Oportunidade ‚û°Ô∏è Venha fazer parte da nossa eq...</td>\n      <td>2</td>\n      <td>[oportunr, venh, fazer, part, equip, vag, Aber...</td>\n    </tr>\n    <tr>\n      <th>94997</th>\n      <td>@96syoo EU SEI üò≠üò≠ √© por isso que significa mui...</td>\n      <td>0</td>\n      <td>[saber, signif, to, feliz, demal, amo, aqu, pr...</td>\n    </tr>\n    <tr>\n      <th>94998</th>\n      <td>@louistsexhes N te conhe√ßo mas posta :D</td>\n      <td>1</td>\n      <td>[n, conhec, postr, d]</td>\n    </tr>\n    <tr>\n      <th>94999</th>\n      <td>meu deus :( https://t.co/BlXazxZeKq</td>\n      <td>0</td>\n      <td>[dar, httpstcoblxazxzekq]</td>\n    </tr>\n  </tbody>\n</table>\n<p>94185 rows √ó 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"%%time\n# After preprocessing, joining the words again in a single string\ndf_train[\"clean_text\"] = df_train[\"processed_tweet\"].apply(lambda x: \" \".join(x))\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-09-14T18:41:56.685332Z","iopub.execute_input":"2022-09-14T18:41:56.685722Z","iopub.status.idle":"2022-09-14T18:41:56.768253Z","shell.execute_reply.started":"2022-09-14T18:41:56.685686Z","shell.execute_reply":"2022-09-14T18:41:56.767260Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"CPU times: user 62.3 ms, sys: 4 ms, total: 66.3 ms\nWall time: 65.4 ms\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                              tweet_text  sentiment  \\\n0      Rio elege maior bancada policial de sua hist√≥r...          2   \n1      fiquei t√£o triste quando eu vi o pre√ßo da c√¢me...          0   \n2      Para Theresa May, seu plano para o Brexit √© a ...          2   \n3      caralho eu quero proteger a danielly em um pot...          0   \n4                             @SiCaetano_ viva o caos :)          1   \n...                                                  ...        ...   \n94995  Cuba e defensor de direitos humanos se unem co...          2   \n94996  #Oportunidade ‚û°Ô∏è Venha fazer parte da nossa eq...          2   \n94997  @96syoo EU SEI üò≠üò≠ √© por isso que significa mui...          0   \n94998            @louistsexhes N te conhe√ßo mas posta :D          1   \n94999                meu deus :( https://t.co/BlXazxZeKq          0   \n\n                                         processed_tweet  \\\n0      [Rio, eleg, mai, banc, polic, hist, Httpstcosg...   \n1                      [fiq, tao, trist, ver, prec, car]   \n2      [ther, may, plan, brexit, unic, opca, httpstco...   \n3         [caralh, querer, proteg, danielly, pot, tadir]   \n4                                             [viv, Cao]   \n...                                                  ...   \n94995  [cub, defen, direit, human, un, contr, chefr, ...   \n94996  [oportunr, venh, fazer, part, equip, vag, Aber...   \n94997  [saber, signif, to, feliz, demal, amo, aqu, pr...   \n94998                              [n, conhec, postr, d]   \n94999                          [dar, httpstcoblxazxzekq]   \n\n                                              clean_text  \n0      Rio eleg mai banc polic hist Httpstcosgxnhzkrh...  \n1                             fiq tao trist ver prec car  \n2         ther may plan brexit unic opca httpstcoeplydbj  \n3                caralh querer proteg danielly pot tadir  \n4                                                viv Cao  \n...                                                  ...  \n94995  cub defen direit human un contr chefr oea inte...  \n94996  oportunr venh fazer part equip vag Abert alunr...  \n94997  saber signif to feliz demal amo aqu pra ver de...  \n94998                                   n conhec postr d  \n94999                             dar httpstcoblxazxzekq  \n\n[94185 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_text</th>\n      <th>sentiment</th>\n      <th>processed_tweet</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Rio elege maior bancada policial de sua hist√≥r...</td>\n      <td>2</td>\n      <td>[Rio, eleg, mai, banc, polic, hist, Httpstcosg...</td>\n      <td>Rio eleg mai banc polic hist Httpstcosgxnhzkrh...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fiquei t√£o triste quando eu vi o pre√ßo da c√¢me...</td>\n      <td>0</td>\n      <td>[fiq, tao, trist, ver, prec, car]</td>\n      <td>fiq tao trist ver prec car</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Para Theresa May, seu plano para o Brexit √© a ...</td>\n      <td>2</td>\n      <td>[ther, may, plan, brexit, unic, opca, httpstco...</td>\n      <td>ther may plan brexit unic opca httpstcoeplydbj</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>caralho eu quero proteger a danielly em um pot...</td>\n      <td>0</td>\n      <td>[caralh, querer, proteg, danielly, pot, tadir]</td>\n      <td>caralh querer proteg danielly pot tadir</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@SiCaetano_ viva o caos :)</td>\n      <td>1</td>\n      <td>[viv, Cao]</td>\n      <td>viv Cao</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94995</th>\n      <td>Cuba e defensor de direitos humanos se unem co...</td>\n      <td>2</td>\n      <td>[cub, defen, direit, human, un, contr, chefr, ...</td>\n      <td>cub defen direit human un contr chefr oea inte...</td>\n    </tr>\n    <tr>\n      <th>94996</th>\n      <td>#Oportunidade ‚û°Ô∏è Venha fazer parte da nossa eq...</td>\n      <td>2</td>\n      <td>[oportunr, venh, fazer, part, equip, vag, Aber...</td>\n      <td>oportunr venh fazer part equip vag Abert alunr...</td>\n    </tr>\n    <tr>\n      <th>94997</th>\n      <td>@96syoo EU SEI üò≠üò≠ √© por isso que significa mui...</td>\n      <td>0</td>\n      <td>[saber, signif, to, feliz, demal, amo, aqu, pr...</td>\n      <td>saber signif to feliz demal amo aqu pra ver de...</td>\n    </tr>\n    <tr>\n      <th>94998</th>\n      <td>@louistsexhes N te conhe√ßo mas posta :D</td>\n      <td>1</td>\n      <td>[n, conhec, postr, d]</td>\n      <td>n conhec postr d</td>\n    </tr>\n    <tr>\n      <th>94999</th>\n      <td>meu deus :( https://t.co/BlXazxZeKq</td>\n      <td>0</td>\n      <td>[dar, httpstcoblxazxzekq]</td>\n      <td>dar httpstcoblxazxzekq</td>\n    </tr>\n  </tbody>\n</table>\n<p>94185 rows √ó 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Checking the repetition of words throught the dataset\nprocessed_words = pd.DataFrame(np.concatenate(df_train[\"processed_tweet\"].values), columns = [\"Appearance_Dataset\"])\nrepetition_freq = processed_words.groupby(\"Appearance_Dataset\").size().sort_values()\nrepetition_freq","metadata":{"execution":{"iopub.status.busy":"2022-09-14T18:41:56.771072Z","iopub.execute_input":"2022-09-14T18:41:56.771450Z","iopub.status.idle":"2022-09-14T18:41:57.847600Z","shell.execute_reply.started":"2022-09-14T18:41:56.771413Z","shell.execute_reply":"2022-09-14T18:41:57.846647Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Appearance_Dataset\nAaaaaaaaaaaaaaaaaaaaaaaaaa        1\nhttpstcopnhioqkgr                 1\nhttpstcopnhdpka                   1\nhttpstcopngvakxmlp                1\nhttpstcopngqatldc                 1\n                              ...  \nquerer                         5871\nbom                            6305\npra                            7254\nir                             9440\nnao                           17974\nLength: 87062, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# After the dataset has been preprocessed, there's still some tuning to be done. This will remove the less frequent appearances.\n\ndf_train[\"tweet_by_frequency\"] = df_train[\"processed_tweet\"].apply(lambda x: removal_words(x,repetition_freq))\ndf_train.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-09-14T18:41:57.848927Z","iopub.execute_input":"2022-09-14T18:41:57.849529Z","iopub.status.idle":"2022-09-14T18:52:26.003902Z","shell.execute_reply.started":"2022-09-14T18:41:57.849491Z","shell.execute_reply":"2022-09-14T18:52:26.002789Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"                                           tweet_text  sentiment  \\\n0   Rio elege maior bancada policial de sua hist√≥r...          2   \n1   fiquei t√£o triste quando eu vi o pre√ßo da c√¢me...          0   \n2   Para Theresa May, seu plano para o Brexit √© a ...          2   \n3   caralho eu quero proteger a danielly em um pot...          0   \n4                          @SiCaetano_ viva o caos :)          1   \n5                          @ppolkiss Parab√©ns mo√ßo :D          1   \n6        Trago verdades #fato https://t.co/DsbkrJgFVj          2   \n7   A cole√ß√£o aumentou, mas o espa√ßo do quaro \"dim...          1   \n8                             @abreujaviera Amigaa :(          0   \n9   fiquei exatos 45 minutos tentando conectar meu...          1   \n10  @uttsrenjun ai n da eu to mto apaixonada no re...          0   \n11  QUERIA AT√â GRAVAR REACTION PRO YOUTUBE MAS NAO...          0   \n12  Vivo oferece acesso gr√°tis ao Amazon Prime Vid...          2   \n13           @pandlernews @theffame √© ciro ou nulo :)          1   \n14  Negro e gay que recusava ser rotulado, autor J...          2   \n15  Nova linha Skyline chega aos fones da Beats no...          2   \n16  @javiercosmico Cuidado con andar controlando g...          0   \n17  Cachorro sumido h√° quase 2 meses √© achado a 15...          2   \n18               @kdkelv pena que n√£o surge efeito :(          0   \n19                  Olhem amanh√£ s√≥ entro √†s 15:15 :)          1   \n\n                                      processed_tweet  \\\n0   [Rio, eleg, mai, banc, polic, hist, Httpstcosg...   \n1                   [fiq, tao, trist, ver, prec, car]   \n2   [ther, may, plan, brexit, unic, opca, httpstco...   \n3      [caralh, querer, proteg, danielly, pot, tadir]   \n4                                          [viv, Cao]   \n5                                     [parab, moc, d]   \n6                  [trag, verdad, httpstcodsbkrjgfvj]   \n7   [colecar, aument, espacr, quar, diminur, invia...   \n8                                             [amigo]   \n9      [fiq, exat, minut, Tent, conect, tecl, Comput]   \n10                  [ai, n, to, mto, apaixon, renjun]   \n11  [querer, ate, Grav, Reaction, pro, Youtub, nao...   \n12  [viv, oferec, acess, gratil, Amazon, prim, vid...   \n13                                         [cir, nul]   \n14  [negr, gay, recu, rotulr, autor, jam, baldwin,...   \n15  [nov, linh, skylin, cheg, fon, beat, Brasil, h...   \n16                    [cuid, con, and, control, Gent]   \n17  [cachorr, sum, ha, qois, mes, ach, km, distanc...   \n18                            [pen, nao, surg, Efeit]   \n19                             [olh, amanh, so, entr]   \n\n                                           clean_text  \\\n0   Rio eleg mai banc polic hist Httpstcosgxnhzkrh...   \n1                          fiq tao trist ver prec car   \n2      ther may plan brexit unic opca httpstcoeplydbj   \n3             caralh querer proteg danielly pot tadir   \n4                                             viv Cao   \n5                                         parab moc d   \n6                      trag verdad httpstcodsbkrjgfvj   \n7   colecar aument espacr quar diminur inviabiliz ...   \n8                                               amigo   \n9              fiq exat minut Tent conect tecl Comput   \n10                         ai n to mto apaixon renjun   \n11  querer ate Grav Reaction pro Youtub nao corag ...   \n12  viv oferec acess gratil Amazon prim vide rival...   \n13                                            cir nul   \n14  negr gay recu rotulr autor jam baldwin Redesco...   \n15  nov linh skylin cheg fon beat Brasil httpstcoy...   \n16                          cuid con and control Gent   \n17  cachorr sum ha qois mes ach km distanc apo don...   \n18                                 pen nao surg Efeit   \n19                                  olh amanh so entr   \n\n                                   tweet_by_frequency  \n0                 [Rio, eleg, mai, banc, polic, hist]  \n1                   [fiq, tao, trist, ver, prec, car]  \n2               [ther, may, plan, brexit, unic, opca]  \n3                       [caralh, querer, proteg, pot]  \n4                                          [viv, Cao]  \n5                                     [parab, moc, d]  \n6                                      [trag, verdad]  \n7     [colecar, aument, espacr, diminur, nov, fot, d]  \n8                                             [amigo]  \n9      [fiq, exat, minut, Tent, conect, tecl, Comput]  \n10                          [ai, n, to, mto, apaixon]  \n11  [querer, ate, Grav, pro, Youtub, nao, corag, n...  \n12  [viv, oferec, acess, gratil, Amazon, prim, vid...  \n13                                         [cir, nul]  \n14              [negr, gay, recu, rotulr, autor, jam]  \n15               [nov, linh, cheg, fon, beat, Brasil]  \n16                    [cuid, con, and, control, Gent]  \n17  [cachorr, sum, ha, qois, mes, ach, km, distanc...  \n18                            [pen, nao, surg, Efeit]  \n19                             [olh, amanh, so, entr]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_text</th>\n      <th>sentiment</th>\n      <th>processed_tweet</th>\n      <th>clean_text</th>\n      <th>tweet_by_frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Rio elege maior bancada policial de sua hist√≥r...</td>\n      <td>2</td>\n      <td>[Rio, eleg, mai, banc, polic, hist, Httpstcosg...</td>\n      <td>Rio eleg mai banc polic hist Httpstcosgxnhzkrh...</td>\n      <td>[Rio, eleg, mai, banc, polic, hist]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fiquei t√£o triste quando eu vi o pre√ßo da c√¢me...</td>\n      <td>0</td>\n      <td>[fiq, tao, trist, ver, prec, car]</td>\n      <td>fiq tao trist ver prec car</td>\n      <td>[fiq, tao, trist, ver, prec, car]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Para Theresa May, seu plano para o Brexit √© a ...</td>\n      <td>2</td>\n      <td>[ther, may, plan, brexit, unic, opca, httpstco...</td>\n      <td>ther may plan brexit unic opca httpstcoeplydbj</td>\n      <td>[ther, may, plan, brexit, unic, opca]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>caralho eu quero proteger a danielly em um pot...</td>\n      <td>0</td>\n      <td>[caralh, querer, proteg, danielly, pot, tadir]</td>\n      <td>caralh querer proteg danielly pot tadir</td>\n      <td>[caralh, querer, proteg, pot]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@SiCaetano_ viva o caos :)</td>\n      <td>1</td>\n      <td>[viv, Cao]</td>\n      <td>viv Cao</td>\n      <td>[viv, Cao]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>@ppolkiss Parab√©ns mo√ßo :D</td>\n      <td>1</td>\n      <td>[parab, moc, d]</td>\n      <td>parab moc d</td>\n      <td>[parab, moc, d]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Trago verdades #fato https://t.co/DsbkrJgFVj</td>\n      <td>2</td>\n      <td>[trag, verdad, httpstcodsbkrjgfvj]</td>\n      <td>trag verdad httpstcodsbkrjgfvj</td>\n      <td>[trag, verdad]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>A cole√ß√£o aumentou, mas o espa√ßo do quaro \"dim...</td>\n      <td>1</td>\n      <td>[colecar, aument, espacr, quar, diminur, invia...</td>\n      <td>colecar aument espacr quar diminur inviabiliz ...</td>\n      <td>[colecar, aument, espacr, diminur, nov, fot, d]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>@abreujaviera Amigaa :(</td>\n      <td>0</td>\n      <td>[amigo]</td>\n      <td>amigo</td>\n      <td>[amigo]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>fiquei exatos 45 minutos tentando conectar meu...</td>\n      <td>1</td>\n      <td>[fiq, exat, minut, Tent, conect, tecl, Comput]</td>\n      <td>fiq exat minut Tent conect tecl Comput</td>\n      <td>[fiq, exat, minut, Tent, conect, tecl, Comput]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>@uttsrenjun ai n da eu to mto apaixonada no re...</td>\n      <td>0</td>\n      <td>[ai, n, to, mto, apaixon, renjun]</td>\n      <td>ai n to mto apaixon renjun</td>\n      <td>[ai, n, to, mto, apaixon]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>QUERIA AT√â GRAVAR REACTION PRO YOUTUBE MAS NAO...</td>\n      <td>0</td>\n      <td>[querer, ate, Grav, Reaction, pro, Youtub, nao...</td>\n      <td>querer ate Grav Reaction pro Youtub nao corag ...</td>\n      <td>[querer, ate, Grav, pro, Youtub, nao, corag, n...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Vivo oferece acesso gr√°tis ao Amazon Prime Vid...</td>\n      <td>2</td>\n      <td>[viv, oferec, acess, gratil, Amazon, prim, vid...</td>\n      <td>viv oferec acess gratil Amazon prim vide rival...</td>\n      <td>[viv, oferec, acess, gratil, Amazon, prim, vid...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>@pandlernews @theffame √© ciro ou nulo :)</td>\n      <td>1</td>\n      <td>[cir, nul]</td>\n      <td>cir nul</td>\n      <td>[cir, nul]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Negro e gay que recusava ser rotulado, autor J...</td>\n      <td>2</td>\n      <td>[negr, gay, recu, rotulr, autor, jam, baldwin,...</td>\n      <td>negr gay recu rotulr autor jam baldwin Redesco...</td>\n      <td>[negr, gay, recu, rotulr, autor, jam]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Nova linha Skyline chega aos fones da Beats no...</td>\n      <td>2</td>\n      <td>[nov, linh, skylin, cheg, fon, beat, Brasil, h...</td>\n      <td>nov linh skylin cheg fon beat Brasil httpstcoy...</td>\n      <td>[nov, linh, cheg, fon, beat, Brasil]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>@javiercosmico Cuidado con andar controlando g...</td>\n      <td>0</td>\n      <td>[cuid, con, and, control, Gent]</td>\n      <td>cuid con and control Gent</td>\n      <td>[cuid, con, and, control, Gent]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Cachorro sumido h√° quase 2 meses √© achado a 15...</td>\n      <td>2</td>\n      <td>[cachorr, sum, ha, qois, mes, ach, km, distanc...</td>\n      <td>cachorr sum ha qois mes ach km distanc apo don...</td>\n      <td>[cachorr, sum, ha, qois, mes, ach, km, distanc...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>@kdkelv pena que n√£o surge efeito :(</td>\n      <td>0</td>\n      <td>[pen, nao, surg, Efeit]</td>\n      <td>pen nao surg Efeit</td>\n      <td>[pen, nao, surg, Efeit]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Olhem amanh√£ s√≥ entro √†s 15:15 :)</td>\n      <td>1</td>\n      <td>[olh, amanh, so, entr]</td>\n      <td>olh amanh so entr</td>\n      <td>[olh, amanh, so, entr]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Transforming the data after the last cleaning process\ndf_train[\"processed_v2\"] = df_train[\"tweet_by_frequency\"].apply(lambda x: \" \".join(x))\ndf_train.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-09-14T18:52:26.007777Z","iopub.execute_input":"2022-09-14T18:52:26.008104Z","iopub.status.idle":"2022-09-14T18:52:26.092100Z","shell.execute_reply.started":"2022-09-14T18:52:26.008076Z","shell.execute_reply":"2022-09-14T18:52:26.090859Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                                           tweet_text  sentiment  \\\n0   Rio elege maior bancada policial de sua hist√≥r...          2   \n1   fiquei t√£o triste quando eu vi o pre√ßo da c√¢me...          0   \n2   Para Theresa May, seu plano para o Brexit √© a ...          2   \n3   caralho eu quero proteger a danielly em um pot...          0   \n4                          @SiCaetano_ viva o caos :)          1   \n5                          @ppolkiss Parab√©ns mo√ßo :D          1   \n6        Trago verdades #fato https://t.co/DsbkrJgFVj          2   \n7   A cole√ß√£o aumentou, mas o espa√ßo do quaro \"dim...          1   \n8                             @abreujaviera Amigaa :(          0   \n9   fiquei exatos 45 minutos tentando conectar meu...          1   \n10  @uttsrenjun ai n da eu to mto apaixonada no re...          0   \n11  QUERIA AT√â GRAVAR REACTION PRO YOUTUBE MAS NAO...          0   \n12  Vivo oferece acesso gr√°tis ao Amazon Prime Vid...          2   \n13           @pandlernews @theffame √© ciro ou nulo :)          1   \n14  Negro e gay que recusava ser rotulado, autor J...          2   \n15  Nova linha Skyline chega aos fones da Beats no...          2   \n16  @javiercosmico Cuidado con andar controlando g...          0   \n17  Cachorro sumido h√° quase 2 meses √© achado a 15...          2   \n18               @kdkelv pena que n√£o surge efeito :(          0   \n19                  Olhem amanh√£ s√≥ entro √†s 15:15 :)          1   \n\n                                      processed_tweet  \\\n0   [Rio, eleg, mai, banc, polic, hist, Httpstcosg...   \n1                   [fiq, tao, trist, ver, prec, car]   \n2   [ther, may, plan, brexit, unic, opca, httpstco...   \n3      [caralh, querer, proteg, danielly, pot, tadir]   \n4                                          [viv, Cao]   \n5                                     [parab, moc, d]   \n6                  [trag, verdad, httpstcodsbkrjgfvj]   \n7   [colecar, aument, espacr, quar, diminur, invia...   \n8                                             [amigo]   \n9      [fiq, exat, minut, Tent, conect, tecl, Comput]   \n10                  [ai, n, to, mto, apaixon, renjun]   \n11  [querer, ate, Grav, Reaction, pro, Youtub, nao...   \n12  [viv, oferec, acess, gratil, Amazon, prim, vid...   \n13                                         [cir, nul]   \n14  [negr, gay, recu, rotulr, autor, jam, baldwin,...   \n15  [nov, linh, skylin, cheg, fon, beat, Brasil, h...   \n16                    [cuid, con, and, control, Gent]   \n17  [cachorr, sum, ha, qois, mes, ach, km, distanc...   \n18                            [pen, nao, surg, Efeit]   \n19                             [olh, amanh, so, entr]   \n\n                                           clean_text  \\\n0   Rio eleg mai banc polic hist Httpstcosgxnhzkrh...   \n1                          fiq tao trist ver prec car   \n2      ther may plan brexit unic opca httpstcoeplydbj   \n3             caralh querer proteg danielly pot tadir   \n4                                             viv Cao   \n5                                         parab moc d   \n6                      trag verdad httpstcodsbkrjgfvj   \n7   colecar aument espacr quar diminur inviabiliz ...   \n8                                               amigo   \n9              fiq exat minut Tent conect tecl Comput   \n10                         ai n to mto apaixon renjun   \n11  querer ate Grav Reaction pro Youtub nao corag ...   \n12  viv oferec acess gratil Amazon prim vide rival...   \n13                                            cir nul   \n14  negr gay recu rotulr autor jam baldwin Redesco...   \n15  nov linh skylin cheg fon beat Brasil httpstcoy...   \n16                          cuid con and control Gent   \n17  cachorr sum ha qois mes ach km distanc apo don...   \n18                                 pen nao surg Efeit   \n19                                  olh amanh so entr   \n\n                                   tweet_by_frequency  \\\n0                 [Rio, eleg, mai, banc, polic, hist]   \n1                   [fiq, tao, trist, ver, prec, car]   \n2               [ther, may, plan, brexit, unic, opca]   \n3                       [caralh, querer, proteg, pot]   \n4                                          [viv, Cao]   \n5                                     [parab, moc, d]   \n6                                      [trag, verdad]   \n7     [colecar, aument, espacr, diminur, nov, fot, d]   \n8                                             [amigo]   \n9      [fiq, exat, minut, Tent, conect, tecl, Comput]   \n10                          [ai, n, to, mto, apaixon]   \n11  [querer, ate, Grav, pro, Youtub, nao, corag, n...   \n12  [viv, oferec, acess, gratil, Amazon, prim, vid...   \n13                                         [cir, nul]   \n14              [negr, gay, recu, rotulr, autor, jam]   \n15               [nov, linh, cheg, fon, beat, Brasil]   \n16                    [cuid, con, and, control, Gent]   \n17  [cachorr, sum, ha, qois, mes, ach, km, distanc...   \n18                            [pen, nao, surg, Efeit]   \n19                             [olh, amanh, so, entr]   \n\n                                         processed_v2  \n0                        Rio eleg mai banc polic hist  \n1                          fiq tao trist ver prec car  \n2                      ther may plan brexit unic opca  \n3                            caralh querer proteg pot  \n4                                             viv Cao  \n5                                         parab moc d  \n6                                         trag verdad  \n7             colecar aument espacr diminur nov fot d  \n8                                               amigo  \n9              fiq exat minut Tent conect tecl Comput  \n10                                ai n to mto apaixon  \n11    querer ate Grav pro Youtub nao corag nct regulr  \n12  viv oferec acess gratil Amazon prim vide rival...  \n13                                            cir nul  \n14                     negr gay recu rotulr autor jam  \n15                      nov linh cheg fon beat Brasil  \n16                          cuid con and control Gent  \n17  cachorr sum ha qois mes ach km distanc apo don...  \n18                                 pen nao surg Efeit  \n19                                  olh amanh so entr  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_text</th>\n      <th>sentiment</th>\n      <th>processed_tweet</th>\n      <th>clean_text</th>\n      <th>tweet_by_frequency</th>\n      <th>processed_v2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Rio elege maior bancada policial de sua hist√≥r...</td>\n      <td>2</td>\n      <td>[Rio, eleg, mai, banc, polic, hist, Httpstcosg...</td>\n      <td>Rio eleg mai banc polic hist Httpstcosgxnhzkrh...</td>\n      <td>[Rio, eleg, mai, banc, polic, hist]</td>\n      <td>Rio eleg mai banc polic hist</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fiquei t√£o triste quando eu vi o pre√ßo da c√¢me...</td>\n      <td>0</td>\n      <td>[fiq, tao, trist, ver, prec, car]</td>\n      <td>fiq tao trist ver prec car</td>\n      <td>[fiq, tao, trist, ver, prec, car]</td>\n      <td>fiq tao trist ver prec car</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Para Theresa May, seu plano para o Brexit √© a ...</td>\n      <td>2</td>\n      <td>[ther, may, plan, brexit, unic, opca, httpstco...</td>\n      <td>ther may plan brexit unic opca httpstcoeplydbj</td>\n      <td>[ther, may, plan, brexit, unic, opca]</td>\n      <td>ther may plan brexit unic opca</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>caralho eu quero proteger a danielly em um pot...</td>\n      <td>0</td>\n      <td>[caralh, querer, proteg, danielly, pot, tadir]</td>\n      <td>caralh querer proteg danielly pot tadir</td>\n      <td>[caralh, querer, proteg, pot]</td>\n      <td>caralh querer proteg pot</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@SiCaetano_ viva o caos :)</td>\n      <td>1</td>\n      <td>[viv, Cao]</td>\n      <td>viv Cao</td>\n      <td>[viv, Cao]</td>\n      <td>viv Cao</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>@ppolkiss Parab√©ns mo√ßo :D</td>\n      <td>1</td>\n      <td>[parab, moc, d]</td>\n      <td>parab moc d</td>\n      <td>[parab, moc, d]</td>\n      <td>parab moc d</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Trago verdades #fato https://t.co/DsbkrJgFVj</td>\n      <td>2</td>\n      <td>[trag, verdad, httpstcodsbkrjgfvj]</td>\n      <td>trag verdad httpstcodsbkrjgfvj</td>\n      <td>[trag, verdad]</td>\n      <td>trag verdad</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>A cole√ß√£o aumentou, mas o espa√ßo do quaro \"dim...</td>\n      <td>1</td>\n      <td>[colecar, aument, espacr, quar, diminur, invia...</td>\n      <td>colecar aument espacr quar diminur inviabiliz ...</td>\n      <td>[colecar, aument, espacr, diminur, nov, fot, d]</td>\n      <td>colecar aument espacr diminur nov fot d</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>@abreujaviera Amigaa :(</td>\n      <td>0</td>\n      <td>[amigo]</td>\n      <td>amigo</td>\n      <td>[amigo]</td>\n      <td>amigo</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>fiquei exatos 45 minutos tentando conectar meu...</td>\n      <td>1</td>\n      <td>[fiq, exat, minut, Tent, conect, tecl, Comput]</td>\n      <td>fiq exat minut Tent conect tecl Comput</td>\n      <td>[fiq, exat, minut, Tent, conect, tecl, Comput]</td>\n      <td>fiq exat minut Tent conect tecl Comput</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>@uttsrenjun ai n da eu to mto apaixonada no re...</td>\n      <td>0</td>\n      <td>[ai, n, to, mto, apaixon, renjun]</td>\n      <td>ai n to mto apaixon renjun</td>\n      <td>[ai, n, to, mto, apaixon]</td>\n      <td>ai n to mto apaixon</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>QUERIA AT√â GRAVAR REACTION PRO YOUTUBE MAS NAO...</td>\n      <td>0</td>\n      <td>[querer, ate, Grav, Reaction, pro, Youtub, nao...</td>\n      <td>querer ate Grav Reaction pro Youtub nao corag ...</td>\n      <td>[querer, ate, Grav, pro, Youtub, nao, corag, n...</td>\n      <td>querer ate Grav pro Youtub nao corag nct regulr</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Vivo oferece acesso gr√°tis ao Amazon Prime Vid...</td>\n      <td>2</td>\n      <td>[viv, oferec, acess, gratil, Amazon, prim, vid...</td>\n      <td>viv oferec acess gratil Amazon prim vide rival...</td>\n      <td>[viv, oferec, acess, gratil, Amazon, prim, vid...</td>\n      <td>viv oferec acess gratil Amazon prim vide rival...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>@pandlernews @theffame √© ciro ou nulo :)</td>\n      <td>1</td>\n      <td>[cir, nul]</td>\n      <td>cir nul</td>\n      <td>[cir, nul]</td>\n      <td>cir nul</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Negro e gay que recusava ser rotulado, autor J...</td>\n      <td>2</td>\n      <td>[negr, gay, recu, rotulr, autor, jam, baldwin,...</td>\n      <td>negr gay recu rotulr autor jam baldwin Redesco...</td>\n      <td>[negr, gay, recu, rotulr, autor, jam]</td>\n      <td>negr gay recu rotulr autor jam</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Nova linha Skyline chega aos fones da Beats no...</td>\n      <td>2</td>\n      <td>[nov, linh, skylin, cheg, fon, beat, Brasil, h...</td>\n      <td>nov linh skylin cheg fon beat Brasil httpstcoy...</td>\n      <td>[nov, linh, cheg, fon, beat, Brasil]</td>\n      <td>nov linh cheg fon beat Brasil</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>@javiercosmico Cuidado con andar controlando g...</td>\n      <td>0</td>\n      <td>[cuid, con, and, control, Gent]</td>\n      <td>cuid con and control Gent</td>\n      <td>[cuid, con, and, control, Gent]</td>\n      <td>cuid con and control Gent</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Cachorro sumido h√° quase 2 meses √© achado a 15...</td>\n      <td>2</td>\n      <td>[cachorr, sum, ha, qois, mes, ach, km, distanc...</td>\n      <td>cachorr sum ha qois mes ach km distanc apo don...</td>\n      <td>[cachorr, sum, ha, qois, mes, ach, km, distanc...</td>\n      <td>cachorr sum ha qois mes ach km distanc apo don...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>@kdkelv pena que n√£o surge efeito :(</td>\n      <td>0</td>\n      <td>[pen, nao, surg, Efeit]</td>\n      <td>pen nao surg Efeit</td>\n      <td>[pen, nao, surg, Efeit]</td>\n      <td>pen nao surg Efeit</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Olhem amanh√£ s√≥ entro √†s 15:15 :)</td>\n      <td>1</td>\n      <td>[olh, amanh, so, entr]</td>\n      <td>olh amanh so entr</td>\n      <td>[olh, amanh, so, entr]</td>\n      <td>olh amanh so entr</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"all_words = df_train[\"processed_v2\"]\n\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title(\"Common words in a Processed Tweet\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-14T21:03:04.962765Z","iopub.execute_input":"2022-09-14T21:03:04.963552Z","iopub.status.idle":"2022-09-14T21:03:05.008160Z","shell.execute_reply.started":"2022-09-14T21:03:04.963505Z","shell.execute_reply":"2022-09-14T21:03:05.006966Z"},"trusted":true},"execution_count":96,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/2702920670.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"processed_v2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwordcloud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_font_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m110\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \"\"\"\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \"\"\"\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mprocess_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0mregexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0;31m# remove 's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         words = [word[:-2] if word.lower().endswith(\"'s\") else word\n","\u001b[0;32m/opt/conda/lib/python3.7/re.py\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"],"ename":"TypeError","evalue":"expected string or bytes-like object","output_type":"error"}]},{"cell_type":"code","source":"# Creating a copy of the original dataframe\ndf_train_copy = df_train.copy()\n\n# Creating an unprocessed dataset based on the complete version, removing the irrelevant columns.\ndf_train_copy = df_train[[\"processed_v2\", \"sentiment\"]]\ndf_train_copy","metadata":{"execution":{"iopub.status.busy":"2022-09-14T18:52:26.093914Z","iopub.execute_input":"2022-09-14T18:52:26.094349Z","iopub.status.idle":"2022-09-14T18:52:26.148962Z","shell.execute_reply.started":"2022-09-14T18:52:26.094308Z","shell.execute_reply":"2022-09-14T18:52:26.147908Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"                                            processed_v2  sentiment\n0                           Rio eleg mai banc polic hist          2\n1                             fiq tao trist ver prec car          0\n2                         ther may plan brexit unic opca          2\n3                               caralh querer proteg pot          0\n4                                                viv Cao          1\n...                                                  ...        ...\n94995  cub defen direit human un contr chefr oea inte...          2\n94996  oportunr venh fazer part equip vag Abert alunr...          2\n94997  saber signif to feliz demal amo aqu pra ver de...          0\n94998                                   n conhec postr d          1\n94999                                                dar          0\n\n[94185 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>processed_v2</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Rio eleg mai banc polic hist</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fiq tao trist ver prec car</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ther may plan brexit unic opca</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>caralh querer proteg pot</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>viv Cao</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94995</th>\n      <td>cub defen direit human un contr chefr oea inte...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>94996</th>\n      <td>oportunr venh fazer part equip vag Abert alunr...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>94997</th>\n      <td>saber signif to feliz demal amo aqu pra ver de...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>94998</th>\n      <td>n conhec postr d</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>94999</th>\n      <td>dar</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>94185 rows √ó 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Now that we've sufficiently cleaned our dataset, preprocessing it with the steps aforementioned, one of the other requirements of this project was to focus at the transformation stage, using different techniques such as Bag Of Words and TF-IDF.\nTherefore, we will now implement it:","metadata":{}},{"cell_type":"code","source":"# Separating data into X and Y\nX = df_train[\"processed_v2\"]\ny = df_train[\"sentiment\"]\n\n# Separating data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    train_size = 0.8,\n                                                    stratify = y,\n                                                    random_state = 42)\n\n# Instantiates the transformer\ntfidf = TfidfVectorizer(use_idf = True)\n\n# Transform data into the output matrix\nX_train_tfidf = tfidf.fit_transform(X_train).todense()\nX_test_tfidf  = tfidf.transform(X_test).todense()","metadata":{"execution":{"iopub.status.busy":"2022-09-14T20:27:38.499627Z","iopub.execute_input":"2022-09-14T20:27:38.500141Z","iopub.status.idle":"2022-09-14T20:27:41.910806Z","shell.execute_reply.started":"2022-09-14T20:27:38.500089Z","shell.execute_reply":"2022-09-14T20:27:41.909761Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"### Multinomial Naive Bayes","metadata":{}},{"cell_type":"code","source":"# Instantiating the model\nmultinomial_model = MultinomialNB()\n\n# Training the model\nmultinomial_model.fit(X_train_tfidf, y_train)\n\n# Assesing the model\nclf_metrics(multinomial_model, X_train_tfidf, X_test_tfidf, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-14T20:27:46.445254Z","iopub.execute_input":"2022-09-14T20:27:46.446317Z","iopub.status.idle":"2022-09-14T20:27:49.692375Z","shell.execute_reply.started":"2022-09-14T20:27:46.446270Z","shell.execute_reply":"2022-09-14T20:27:49.691276Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  FutureWarning,\n","output_type":"stream"},{"name":"stdout","text":"# ============================================\n\nTraining Assessment Metrics:\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  FutureWarning,\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.75      0.77      0.76     25158\n           1       0.72      0.68      0.70     25025\n           2       0.87      0.90      0.88     25165\n\n    accuracy                           0.78     75348\n   macro avg       0.78      0.78      0.78     75348\nweighted avg       0.78      0.78      0.78     75348\n\n# ============================================\n\nTest Assessment Metrics:\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  FutureWarning,\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.72      0.74      0.73      6290\n           1       0.68      0.64      0.66      6256\n           2       0.86      0.89      0.87      6291\n\n    accuracy                           0.76     18837\n   macro avg       0.75      0.76      0.75     18837\nweighted avg       0.75      0.76      0.75     18837\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Neural Network Model","metadata":{}},{"cell_type":"markdown","source":"#### In this section, a neural network model will be used. The steps seen were all taught during module ministered by professor Cec√≠lia Fl√°via, as well as the configurations necessary to implement it.","metadata":{}},{"cell_type":"code","source":"# Separating data into train and test\nX_train, X_test, y_train, y_test = train_test_split(df_train[\"processed_v2\"],\n                                                    df_train[\"sentiment\"],\n                                                    test_size=0.2,\n                                                    stratify = y,\n                                                    random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-09-14T20:35:36.660197Z","iopub.execute_input":"2022-09-14T20:35:36.661396Z","iopub.status.idle":"2022-09-14T20:35:36.706895Z","shell.execute_reply.started":"2022-09-14T20:35:36.661340Z","shell.execute_reply":"2022-09-14T20:35:36.705976Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# Separating data into train and validation\nX_train, X_val, y_train, y_val = train_test_split(X_train,\n                                                  y_train,\n                                                  test_size=0.1,\n                                                  random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-09-14T20:36:25.231119Z","iopub.execute_input":"2022-09-14T20:36:25.231797Z","iopub.status.idle":"2022-09-14T20:36:25.249108Z","shell.execute_reply.started":"2022-09-14T20:36:25.231762Z","shell.execute_reply":"2022-09-14T20:36:25.248213Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"# Establishing boundries\nvocab_size = 20000\nembedding_dim = 16 # which is the size of each embedding vector\nmax_length = 250","metadata":{"execution":{"iopub.status.busy":"2022-09-14T20:36:28.550303Z","iopub.execute_input":"2022-09-14T20:36:28.550676Z","iopub.status.idle":"2022-09-14T20:36:28.557616Z","shell.execute_reply.started":"2022-09-14T20:36:28.550644Z","shell.execute_reply":"2022-09-14T20:36:28.556388Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"# Using the Tokenizer\ntokenizer = Tokenizer(num_words = vocab_size)\ntokenizer.fit_on_texts(X_train)\nsequences = tokenizer.texts_to_sequences(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-09-14T20:36:31.555180Z","iopub.execute_input":"2022-09-14T20:36:31.555891Z","iopub.status.idle":"2022-09-14T20:36:33.653763Z","shell.execute_reply.started":"2022-09-14T20:36:31.555855Z","shell.execute_reply":"2022-09-14T20:36:33.652756Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"# Adjusting data\npadded = pad_sequences(sequences,maxlen=max_length)\nval_sequences = tokenizer.texts_to_sequences(X_val)\nval_padded = pad_sequences(val_sequences,maxlen=max_length)\ntest_sequences = tokenizer.texts_to_sequences(X_test)\ntest_padded = pad_sequences(test_sequences,maxlen=max_length)","metadata":{"execution":{"iopub.status.busy":"2022-09-14T20:36:34.173688Z","iopub.execute_input":"2022-09-14T20:36:34.174034Z","iopub.status.idle":"2022-09-14T20:36:34.712586Z","shell.execute_reply.started":"2022-09-14T20:36:34.174004Z","shell.execute_reply":"2022-09-14T20:36:34.711619Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":"**Some observations about the next step, which is the instantiation of the model.**\n\n-  *Relu* (Rectified Linear Unit) activation function in Keras is going to be used, because it returns 0 if it receives any negative input, but for any positive value x it returns that value back.\n\n**While**\n\n- *Softmax* is going to be used because it transforms an unconstrained n-dimensional vector into a valid probability distribution.","metadata":{}},{"cell_type":"code","source":"# Instantiating the model\nneural_model = Sequential()\nneural_model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\nneural_model.add(Flatten())\nneural_model.add(Dense(50, activation = \"relu\"))\nneural_model.add(Dense(10))\nneural_model.add(Dense(3))\nneural_model.add(Activation(\"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2022-09-14T20:36:38.150947Z","iopub.execute_input":"2022-09-14T20:36:38.151376Z","iopub.status.idle":"2022-09-14T20:36:38.192827Z","shell.execute_reply.started":"2022-09-14T20:36:38.151339Z","shell.execute_reply":"2022-09-14T20:36:38.191903Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"markdown","source":"#### In the setup of the learning metrics, the optimizer \"*Adam*\" will be used.\n- *Adam* optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.","metadata":{}},{"cell_type":"markdown","source":"In this case, the only difference to what was implemented during Cec√≠lia's lessons is the fact that Sparse Categorical Corssentropy is going to be used because the data has two or more label classes, provided as integers.","metadata":{}},{"cell_type":"code","source":"# Learning metrics\nneural_model.compile(optimizer = \"adam\",\n              loss = \"sparse_categorical_crossentropy\",\n              metrics = [\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-09-14T20:36:43.301467Z","iopub.execute_input":"2022-09-14T20:36:43.302094Z","iopub.status.idle":"2022-09-14T20:36:43.313828Z","shell.execute_reply.started":"2022-09-14T20:36:43.302058Z","shell.execute_reply":"2022-09-14T20:36:43.312874Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"# Training the model\ncallbacks = [\n    ModelCheckpoint(\n        neural_model.save(filepath=\"1stmodel.keras\"),\n        save_best_only=True,\n        monitor=\"val_loss\"\n    )\n]\n\nresults = neural_model.fit(\n padded, y_train,\n epochs= 5,\n batch_size = 64,\n validation_data = (val_padded, y_val)\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-14T20:36:46.912631Z","iopub.execute_input":"2022-09-14T20:36:46.914542Z","iopub.status.idle":"2022-09-14T20:37:03.138973Z","shell.execute_reply.started":"2022-09-14T20:36:46.914495Z","shell.execute_reply":"2022-09-14T20:37:03.138068Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"Epoch 1/5\n1060/1060 [==============================] - 4s 3ms/step - loss: 0.5872 - accuracy: 0.3422 - val_loss: 0.4977 - val_accuracy: 0.4397\nEpoch 2/5\n1060/1060 [==============================] - 3s 3ms/step - loss: 0.4249 - accuracy: 0.3511 - val_loss: 0.4822 - val_accuracy: 0.2909\nEpoch 3/5\n1060/1060 [==============================] - 3s 3ms/step - loss: 0.3811 - accuracy: 0.3492 - val_loss: 0.4920 - val_accuracy: 0.3866\nEpoch 4/5\n1060/1060 [==============================] - 3s 3ms/step - loss: 0.3462 - accuracy: 0.3503 - val_loss: 0.5062 - val_accuracy: 0.3497\nEpoch 5/5\n1060/1060 [==============================] - 3s 3ms/step - loss: 0.3149 - accuracy: 0.3483 - val_loss: 0.5612 - val_accuracy: 0.3854\n","output_type":"stream"}]},{"cell_type":"code","source":"# Loading the best model generated\nneural_model = load_model(\"1stmodel.keras\")\n\n# Applying test data into the model to check how it goes\ntest_loss, test_accuracy = neural_model.evaluate(test_padded,y_test)\nprint(f\"Test accuracy for this model: {test_accuracy:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-14T20:37:11.342832Z","iopub.execute_input":"2022-09-14T20:37:11.344014Z","iopub.status.idle":"2022-09-14T20:37:12.777788Z","shell.execute_reply.started":"2022-09-14T20:37:11.343970Z","shell.execute_reply":"2022-09-14T20:37:12.776747Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"589/589 [==============================] - 1s 2ms/step - loss: 1.0992 - accuracy: 0.8784\nTest accuracy for this model: 0.88\n","output_type":"stream"}]},{"cell_type":"code","source":"# Assesing the model\nneural_network_clf(neural_model, X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-14T20:39:48.069099Z","iopub.execute_input":"2022-09-14T20:39:48.069774Z","iopub.status.idle":"2022-09-14T20:39:48.179024Z","shell.execute_reply.started":"2022-09-14T20:39:48.069738Z","shell.execute_reply":"2022-09-14T20:39:48.177366Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"# ============================================\n\nTraining Assessment Metrics:\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/3511054498.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assesing the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mneural_network_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneural_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_17/778361254.py\u001b[0m in \u001b[0;36mneural_network_clf\u001b[0;34m(estimator, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTraining Assessment Metrics:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0my_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0my_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1749\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m-> 3038\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3458\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3459\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3460\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3381\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3382\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3383\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1537 predict_step\n        return self(x, training=False)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/sequential.py:369 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:415 call\n        inputs, training=training, mask=mask)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py:254 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer dense_6 is incompatible with the layer: expected axis -1 of input shape to have value 4000 but received input with shape (None, 16)\n"],"ename":"ValueError","evalue":"in user code:\n\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1537 predict_step\n        return self(x, training=False)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/sequential.py:369 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:415 call\n        inputs, training=training, mask=mask)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py:254 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer dense_6 is incompatible with the layer: expected axis -1 of input shape to have value 4000 but received input with shape (None, 16)\n","output_type":"error"}]},{"cell_type":"markdown","source":"# Final Findings & Considerations","metadata":{"id":"0decf71e","outputId":"731b1602-10f8-4683-cb17-76ee8aa59f0a"}},{"cell_type":"markdown","source":"This project aimed to develop a model to detect sentiment in a Tweet. In general, the models used presented a good performance. \nDifferent Natural Language Processing techniques were implemented to clean the text, handle specific cases and test out some of the acquired knowledge through the course, such as Bag of Words with TF-IDF.\nThe models chosen for this sentiment analysis prediction were Multinomial NB as well as Neural Networks.\nNote that even though the Multinomial NB presented an accuracy of 78%, while the Neural Network technique implemented has 88% of accuracy, and despite those percentages indicating that it's possible to analyze the sentiment of a Tweet based on the data provided, it's necessary to have an alignment with business to understand the context in which these models should be applied.\nThere was an effort to clean the leaked data inherent to this dataset; thus, the importance of understanding in which context this should be applied since a young user mentioning one‚Äôs dissatisfaction with a daily life occurrence, will not chose the same words/phrase patterns of a more mature user expressing dissatisfaction with a brand/service/product.\n\nBrazilian Portuguese is very complex and rich in terms of slangs, phrase patterns and communication in general; therefore, it‚Äôs of extreme importance to choose well the cleaning and preprocessing stages to fine tune it to the desired audience.","metadata":{}}]}